{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from visdom import Visdom\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import Reader\n",
    "\n",
    "import time\n",
    "\n",
    "from dotmap import DotMap\n",
    "\n",
    "config = DotMap({\n",
    "    \"training\": True,\n",
    "    \"batch\": 32,\n",
    "    \"workers\": 0,\n",
    "    \"epoch\": 200,\n",
    "    \"in_scale\": 256,\n",
    "    \"out_scale\": 256\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1x1 convolution\n",
    "def conv_one(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm3d(in_channel),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv3d(in_channel, out_channel, 1,\n",
    "                  bias=False)\n",
    "    )\n",
    "\n",
    "# 3x3 convolution\n",
    "def conv_thr(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm3d(in_channel),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv3d(in_channel, out_channel, 3,\n",
    "                  padding=1, bias=False)\n",
    "    )\n",
    "\n",
    "# dilated convolution\n",
    "def conv_dil(in_channel, out_channel, dilation=1):\n",
    "    return nn.Conv3d(in_channel, out_channel, 3,\n",
    "                  padding=[dilation,dilation,1],\n",
    "                  dilation=[dilation,dilation,1],\n",
    "                  bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASPP\n",
    "class ASPP(nn.Module):\n",
    "    \"\"\"Atrous Spatial Pyramid Pooling\"\"\"\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ASPP, self).__init__()\n",
    "        self.stages = nn.Module()\n",
    "        \n",
    "        pyramids = [6, 12, 18, 24]\n",
    "        \n",
    "        for i, dilation in enumerate(pyramids):\n",
    "            self.stages.add_module(\n",
    "                \"aspp{}\".format(i),\n",
    "                conv_dil(in_channels, out_channels, dilation)\n",
    "            )\n",
    "        \n",
    "        for m in self.stages.children():\n",
    "            nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = 0\n",
    "        for stage in self.stages.children():\n",
    "            h += stage(x)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel=None):\n",
    "        super(Residual, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        \n",
    "        if out_channel is None:\n",
    "            out_channel = in_channel\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            conv_one(in_channel, out_channel // 2),\n",
    "            conv_thr(out_channel // 2, out_channel // 2),\n",
    "            conv_one(out_channel // 2, out_channel)\n",
    "        )\n",
    "        \n",
    "        self.skip_layer = None\n",
    "        if in_channel != out_channel:\n",
    "            self.skip_layer = nn.Conv3d(in_channel, out_channel, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        \n",
    "        out = self.conv_block(x)\n",
    "        \n",
    "        if self.skip_layer is not None:\n",
    "            skip = self.skip_layer(x)\n",
    "        \n",
    "        out += skip\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourglass\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, size, channels):\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.size = size\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.skip_layers = nn.ModuleList(\n",
    "            [Residual(\n",
    "                self.channels\n",
    "            ) for i in range(self.size)]\n",
    "        )\n",
    "        self.low_layers = nn.ModuleList(\n",
    "            [Residual(\n",
    "                self.channels\n",
    "            ) for i in range(self.size)]\n",
    "        )\n",
    "        self.mid = Residual(self.channels)\n",
    "        self.up_layers = nn.ModuleList(\n",
    "            [Residual(\n",
    "                self.channels\n",
    "            ) for i in range(self.size)]\n",
    "        )\n",
    "        self.max_pool = nn.MaxPool3d((1, 2, 2), stride=(1, 2, 2))\n",
    "        self.upsample = nn.Upsample(scale_factor=(1, 2, 2), mode='trilinear', align_corners=False)\n",
    "        # nearest not working with tuple(1, 2, 2). so trilinear\n",
    "\n",
    "    def forward(self, x):\n",
    "        inner = x\n",
    "\n",
    "        skip_outputs = list()\n",
    "        for skip, low in zip(self.skip_layers, self.low_layers):\n",
    "            s = skip(inner)\n",
    "            skip_outputs.append(s)\n",
    "            inner = self.max_pool(inner)\n",
    "            inner = low(inner)\n",
    "        \n",
    "        out = self.mid(inner)\n",
    "\n",
    "        for skip, up in zip(reversed(skip_outputs), reversed(self.up_layers)):\n",
    "            out = skip + self.upsample(up(out))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, features, internal_size=6):\n",
    "        super(Model, self).__init__()\n",
    "        self.features = features\n",
    "        self.internal_size = internal_size\n",
    "        \n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 7, stride=(1, 2, 2),\n",
    "                      padding=3, bias=False),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Residual(8, 16),\n",
    "        )\n",
    "        \n",
    "        self.mid_conv = nn.Sequential(\n",
    "            nn.MaxPool3d((1, 2, 2), stride=(1, 2, 2)),\n",
    "            Residual(16, 32),\n",
    "            Residual(32, self.features)\n",
    "        )\n",
    "        \n",
    "        self.skip_conv = Residual(16, 16)\n",
    "        \n",
    "        self.hourglass = Hourglass(self.internal_size, self.features)\n",
    "        \n",
    "        self.up_conv = nn.Sequential(\n",
    "            Residual(self.features, self.features),\n",
    "            nn.Upsample(scale_factor=(1, 4, 4), mode='trilinear', align_corners=False)\n",
    "        )\n",
    "        \n",
    "        self.aspp = ASPP(self.features, self.features)\n",
    "        \n",
    "        self.out_conv = nn.Sequential(\n",
    "            conv_one(self.features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        init = self.init_conv(x)\n",
    "        mid = self.mid_conv(init)\n",
    "        \n",
    "        hg = self.hourglass(mid)\n",
    "        \n",
    "        up = self.up_conv(hg)\n",
    "        \n",
    "        out = self.out_conv(up)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    Reader.Liver3LayerSH(\n",
    "        augment = True\n",
    "    ),\n",
    "    config.batch,\n",
    "    shuffle=(config.training),\n",
    "    pin_memory=True,\n",
    "    num_workers=config.workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "model = Model(64)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)#lr=0.00025)\n",
    "criterion = nn.BCELoss(torch.ones(config.batch, dtype=torch.float64))\n",
    "# cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "training = True\n",
    "\n",
    "visual = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = True\n",
    "model = model.train()\n",
    "counter = 0\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#Batch, Channel, Depth, Height, Width\n",
    "# dummy_input = torch.autograd.Variable(\n",
    "#     torch.rand(config.batch, 1, 3, config.in_scale, config.in_scale)\n",
    "# )\n",
    "# dummy_input = dummy_input.to(device)\n",
    "# writer.add_graph(model, (dummy_input, ))\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "for epoch in range(1, config.epoch+1):\n",
    "    with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "        progress.set_description('Epoch %d' % epoch)\n",
    "        \n",
    "        with torch.set_grad_enabled(training):\n",
    "            for images, labels in loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                images = images.float()\n",
    "                input_image = images\n",
    "                images = images.to(device)\n",
    "\n",
    "                labels = labels.float()\n",
    "#                 if np.max(labels.data.numpy()) < 1 :\n",
    "#                     progress.update(1)\n",
    "#                     continue\n",
    "                \n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                output = model(images)\n",
    "                \n",
    "                if training:\n",
    "                    out_image = output.cpu().data\n",
    "                    label_image = labels.cpu().data\n",
    "                    \n",
    "                    weight = []\n",
    "                    for images in label_image.numpy().squeeze():\n",
    "                        weight_batch = []\n",
    "                        for image in images:\n",
    "                            value = np.ceil(image)\n",
    "                            if np.sum(image) > 0:\n",
    "                                value *= (np.sum(1-image) / np.sum(image))-1\n",
    "                            value += 1\n",
    "                            weight_batch.append(value)\n",
    "                        weight.append(weight_batch)\n",
    "                    \n",
    "                    weight = np.array(weight)\n",
    "                    \n",
    "                    criterion.weight = torch.tensor(weight).to(device)\n",
    "                    \n",
    "                    loss = criterion(output.squeeze(), labels.squeeze())\n",
    "                    loss = torch.mean(loss)\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    progress.set_postfix(loss=float(loss.item()))\n",
    "                    \n",
    "                    input_image = input_image.cpu().data\n",
    "                    input_image = input_image.view(-1, config.in_scale, config.in_scale)\n",
    "                    input_image = input_image.numpy()\n",
    "                    input_image = input_image.squeeze()\n",
    "                    input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "                    input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "                    input_image = [np.array(layer) for layer in input_image]\n",
    "                    input_image = np.asarray(input_image)\n",
    "                    input_image *= 255\n",
    "                    input_image = np.clip(input_image, 0, 255)\n",
    "                    input_depth = len(input_image)\n",
    "                    input_image = input_image.repeat(3, axis=0)\n",
    "                    input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "                    \n",
    "                    out_image = out_image.view(-1, config.out_scale, config.out_scale)\n",
    "#                     out_image = out_image.view(-1, 64, 64)\n",
    "                    out_image = out_image.numpy()\n",
    "                    out_image = out_image.squeeze()\n",
    "                    out_image = [Image.fromarray(layer, 'F') for layer in out_image]\n",
    "                    out_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in out_image]\n",
    "                    out_image = [np.array(layer) for layer in out_image]\n",
    "                    out_image = np.asarray(out_image)\n",
    "                    out_image *= 255\n",
    "                    out_image = np.clip(out_image, 0, 255)\n",
    "                    out_depth = len(out_image)\n",
    "                    out_image = out_image.repeat(3, axis=0)\n",
    "                    out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "                    \n",
    "                    label_image = label_image.view(-1, config.out_scale, config.out_scale)\n",
    "#                     label_image = label_image.view(-1, 64, 64)\n",
    "                    label_image = label_image.numpy()\n",
    "                    label_image = label_image.squeeze()\n",
    "                    label_image = [Image.fromarray(layer, 'F') for layer in label_image]\n",
    "                    label_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in label_image]\n",
    "                    label_image = [np.array(layer) for layer in label_image]\n",
    "                    label_image = np.asarray(label_image)\n",
    "                    label_image *= 255\n",
    "                    label_image = np.clip(label_image, 0, 255)\n",
    "                    label_depth = len(label_image)\n",
    "                    label_image = label_image.repeat(3, axis=0)\n",
    "                    label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "                    \n",
    "                    visual.images(\n",
    "                        tensor=input_image, nrow=9,\n",
    "                        win='input',\n",
    "                        opts=dict(title='input')\n",
    "                    )\n",
    "                    \n",
    "                    visual.images(\n",
    "                        tensor=out_image, nrow=9,\n",
    "                        win='output',\n",
    "                        opts=dict(title='output')\n",
    "                    )\n",
    "                    visual.images(\n",
    "                        tensor=label_image, nrow=9,\n",
    "                        win='label',\n",
    "                        opts=dict(title='label')\n",
    "                    )\n",
    "                    \n",
    "                    writer.add_scalar('data/loss', float(loss.item()), counter)\n",
    "                    \n",
    "                    progress.update(1)\n",
    "                    \n",
    "                    counter += 1\n",
    "                    \n",
    "                else:\n",
    "                    raise Exception('There\\'s no Validation code available.')\n",
    "        \n",
    "        # save model\n",
    "        save_epoch = epoch + 261\n",
    "        torch.save({\n",
    "            'epoch': save_epoch,\n",
    "            'state': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict()\n",
    "        }, 'save/256_justUpscaleX4/'+str(save_epoch)+'.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "save_epoch = config.epoch\n",
    "save_epoch = 62\n",
    "torch.save({\n",
    "    'epoch': save_epoch,\n",
    "    'state': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, 'save/256_justUpscaleX4/'+str(save_epoch)+'.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = Model(64)\n",
    "pretrained_model = torch.load('save/256_justUpscaleX4/261.save')\n",
    "model.load_state_dict(pretrained_model['state'])\n",
    "\n",
    "model = model.eval()\n",
    "# cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "training = False\n",
    "\n",
    "visual = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    Reader.LiverData(\n",
    "        augment = False,\n",
    "        paths = ['Data/3Dircadb/']\n",
    "    ),\n",
    "    1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a CT\n",
    "training = False\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "num_valid_data = 0\n",
    "meanVOE = 0\n",
    "meanDICE = 0\n",
    "meanRVD = 0\n",
    "DICE_list = []\n",
    "\n",
    "a_sum = 0\n",
    "b_sum = 0\n",
    "aub_sum = 0\n",
    "anb_sum = 0\n",
    "\n",
    "a_sum_in = 0\n",
    "b_sum_in = 0\n",
    "aub_sum_in = 0\n",
    "anb_sum_in = 0\n",
    "\n",
    "with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "    progress.set_description('Testing')\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for idx, (image, label) in enumerate(loader):\n",
    "            \n",
    "            image = image.float()\n",
    "            image = image.squeeze()\n",
    "            \n",
    "            output = []\n",
    "            \n",
    "            for index in range(0, len(image), 3):\n",
    "                final = 0\n",
    "                if index+3 > len(image):\n",
    "                    final = index+3 - len(image)\n",
    "                    index = len(image) - 3\n",
    "                    \n",
    "                input_cell = image[index:index+3]\n",
    "                input_cell = input_cell.unsqueeze(0).unsqueeze(0)\n",
    "                input_cell = input_cell.to(device)\n",
    "                out_cell = model(input_cell)\n",
    "                out_cell = out_cell.squeeze()\n",
    "                if final is 0:\n",
    "                    feed = out_cell.cpu().data.numpy()\n",
    "                    for layer in feed:\n",
    "                        output.append(layer)\n",
    "                else:\n",
    "                    feed = out_cell.narrow(0, final, 3-final)\n",
    "                    feed = feed.cpu().data.numpy()\n",
    "                    for layer in feed:\n",
    "                        output.append(layer)\n",
    "            \n",
    "            label = label.float()\n",
    "\n",
    "            if training:\n",
    "                raise Exception('There\\'s no Training code available.')\n",
    "            else:\n",
    "                input_image = image.cpu().data\n",
    "                input_image = input_image.view(-1, config.in_scale, config.in_scale)\n",
    "                input_image = input_image.numpy()\n",
    "                input_image = input_image.squeeze()\n",
    "                input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "                input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "                input_image = [np.array(layer) for layer in input_image]\n",
    "                input_image = np.asarray(input_image)\n",
    "                input_image *= 255\n",
    "                input_image = np.clip(input_image, 0, 255)\n",
    "                input_depth = len(input_image)\n",
    "                input_image = input_image.repeat(3, axis=0)\n",
    "                input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "\n",
    "                #threshold\n",
    "                output = np.asarray(output)\n",
    "                output = np.ceil(output - 0.81)\n",
    "                \n",
    "                out_image = [Image.fromarray(layer, 'F') for layer in output]\n",
    "                out_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in out_image]\n",
    "                out_image = [np.array(layer) for layer in out_image]\n",
    "                out_image = np.asarray(out_image)\n",
    "                out_image *= 255\n",
    "                out_image = np.clip(out_image, 0, 255)\n",
    "                out_depth = len(out_image)\n",
    "                out_image = out_image.repeat(3, axis=0)\n",
    "                out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "\n",
    "                label_image = label.data\n",
    "                label_image = label_image.view(-1, config.out_scale, config.out_scale)\n",
    "                label_image = label_image.numpy()\n",
    "                label_image = label_image.squeeze()\n",
    "                label_image = [Image.fromarray(layer, 'F') for layer in label_image]\n",
    "                label_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in label_image]\n",
    "                label_image = [np.array(layer) for layer in label_image]\n",
    "                label_image = np.asarray(label_image)\n",
    "                label_image *= 255\n",
    "                label_image = np.clip(label_image, 0, 255)\n",
    "                label_depth = len(label_image)\n",
    "                label_image = label_image.repeat(3, axis=0)\n",
    "                label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "                \n",
    "#                 for out_layer, label_layer in zip(out_image, label_image):\n",
    "#                     out_layer[0][:] = 0 #R\n",
    "#                     out_layer[1] = label_layer[1] #G\n",
    "#                     out_layer[2][:] = 0 #B\n",
    "\n",
    "                visual.images(\n",
    "                    tensor=input_image, nrow=6,\n",
    "                    win='input',\n",
    "                    opts=dict(title='input')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=out_image, nrow=6,\n",
    "                    win='output',\n",
    "                    opts=dict(title='output')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=label_image, nrow=6,\n",
    "                    win='label',\n",
    "                    opts=dict(title='label')\n",
    "                )\n",
    "\n",
    "#                 #threshold\n",
    "#                 output = np.asarray(output)\n",
    "#                 output = np.ceil(output - 0.8)\n",
    "                \n",
    "                label = label.data.numpy().squeeze()\n",
    "                label = np.ceil(label - 0.81)\n",
    "\n",
    "                a = np.sum(label)\n",
    "                b = np.sum(output)\n",
    "                aub = np.sum(np.ceil((label + output) / 2))\n",
    "                anb = np.sum(label * output)\n",
    "                \n",
    "                anb_image = label * output\n",
    "                anb_image = [Image.fromarray(layer, 'F') for layer in anb_image]\n",
    "                anb_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in anb_image]\n",
    "                anb_image = [np.array(layer) for layer in anb_image]\n",
    "                anb_image = np.asarray(anb_image)\n",
    "                anb_image *= 255\n",
    "                anb_image = np.clip(anb_image, 0, 255)\n",
    "                anb_depth = len(anb_image)\n",
    "                anb_image = anb_image.repeat(3, axis=0)\n",
    "                anb_image = np.reshape(anb_image, (anb_depth, 3, 64,64))\n",
    "                \n",
    "                visual.images(\n",
    "                    tensor=anb_image, nrow=6,\n",
    "                    win='anb',\n",
    "                    opts=dict(title='anb')\n",
    "                )\n",
    "                \n",
    "                a_sum += a\n",
    "                b_sum += b\n",
    "                aub_sum += aub\n",
    "                anb_sum += anb\n",
    "\n",
    "                if a > 1:\n",
    "                    a_sum_in += a\n",
    "                    b_sum_in += b\n",
    "                    aub_sum_in += aub\n",
    "                    anb_sum_in += anb\n",
    "                    \n",
    "                    #Volume Overlap Error\n",
    "                    VOE = 1 - (anb / aub)\n",
    "\n",
    "                    #DICE score\n",
    "                    DICE = (2 * anb) / (a + b)\n",
    "\n",
    "                    #Relative Volume Difference\n",
    "                    RVD = (b - a) / a\n",
    "\n",
    "                    meanVOE += VOE\n",
    "                    meanDICE += DICE\n",
    "                    meanRVD += RVD\n",
    "\n",
    "                    num_valid_data += 1\n",
    "                    \n",
    "                    DICE_list.append(DICE)\n",
    "                    \n",
    "#                 if DICE > 0.94 and a > 1:\n",
    "#                     for idx, layer in enumerate(output):\n",
    "#                         img = Image.fromarray(layer*255)\n",
    "#                         img = img.convert(\"RGB\")\n",
    "#                         img.save(\"image/out{}.png\".format(str(idx)))\n",
    "                \n",
    "                progress.set_postfix(loss=float(DICE))\n",
    "\n",
    "                progress.update(1)\n",
    "\n",
    "meanVOE /= num_valid_data\n",
    "print('VOE:  ', meanVOE)\n",
    "meanDICE /= num_valid_data\n",
    "print('DICE: ', meanDICE)\n",
    "meanRVD /= num_valid_data\n",
    "print('RVD:  ', meanRVD)\n",
    "\n",
    "global_DICE = (2 * anb_sum) / (a_sum + b_sum)\n",
    "global_VOE = 1 - (anb_sum / aub_sum)\n",
    "global_RVD = (b_sum - a_sum) / a_sum\n",
    "print(\"all\")\n",
    "print(global_DICE, global_VOE, global_RVD)\n",
    "\n",
    "global_DICE = (2 * anb_sum_in) / (a_sum_in + b_sum_in)\n",
    "global_VOE = 1 - (anb_sum_in / aub_sum_in)\n",
    "global_RVD = (b_sum_in - a_sum_in) / a_sum_in\n",
    "print(\"except\")\n",
    "print(global_DICE, global_VOE, global_RVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDICE = []\n",
    "for value in DICE_list:\n",
    "    if value > 0.3:\n",
    "        newDICE.append(value)\n",
    "print(sum(newDICE)/len(newDICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for value in DICE_list:\n",
    "    print(value)\n",
    "    if value > 0.1:\n",
    "        num += 1\n",
    "print(sum(DICE_list)/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "training = False\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "num_valid_data = 0\n",
    "meanVOE = 0\n",
    "meanDICE = 0\n",
    "meanRVD = 0\n",
    "\n",
    "with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "    progress.set_description('Testing')\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for image, label in loader:\n",
    "            \n",
    "            image = image.float()\n",
    "            image = image.to(device)\n",
    "            \n",
    "            label = label.float()\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output = model(image)\n",
    "            \n",
    "            if training:\n",
    "                raise Exception('There\\'s no Training code available.')\n",
    "            else:\n",
    "                input_image = image.cpu().data\n",
    "                input_image = input_image.view(-1, 256, 256)\n",
    "                input_image = input_image.numpy()\n",
    "                input_image = input_image.squeeze()\n",
    "                input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "                input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "                input_image = [np.array(layer) for layer in input_image]\n",
    "                input_image = np.asarray(input_image)\n",
    "                input_image[input_image < 0] = 0\n",
    "                input_image *= 255\n",
    "                input_depth = len(input_image)\n",
    "                input_image = input_image.repeat(3, axis=0)\n",
    "                input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "                \n",
    "                out_image = output.cpu().data\n",
    "                out_image = out_image.view(-1, 64, 64)\n",
    "                out_image = out_image.numpy()\n",
    "                out_image = out_image.squeeze()\n",
    "                out_depth = len(out_image)\n",
    "                out_image = out_image.repeat(3, axis=0)\n",
    "                out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "                \n",
    "                label_image = label.cpu().data\n",
    "                label_image = label_image.view(-1, 64, 64)\n",
    "                label_image = label_image.numpy()\n",
    "                label_image = label_image.squeeze()\n",
    "                label_depth = len(label_image)\n",
    "                label_image = label_image.repeat(3, axis=0)\n",
    "                label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "                \n",
    "#                 for out_layer, label_layer in zip(out_image, label_image):\n",
    "#                     out_layer[0][:] = 0 #R\n",
    "#                     out_layer[1] = label_layer[1] #G\n",
    "#                     out_layer[2][:] = 0 #B\n",
    "\n",
    "                visual.images(\n",
    "                    tensor=input_image, nrow=12,\n",
    "                    win='input',\n",
    "                    opts=dict(title='input')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=out_image, nrow=12,\n",
    "                    win='output',\n",
    "                    opts=dict(title='output')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=label_image, nrow=12,\n",
    "                    win='label',\n",
    "                    opts=dict(title='label')\n",
    "                )\n",
    "\n",
    "                #threshold\n",
    "                out_image = np.ceil(out_image - 0.5)\n",
    "\n",
    "                for label_layer, out_layer in zip(label_image, out_image):\n",
    "                    #BASIC values\n",
    "                    a = np.sum(label_layer)\n",
    "                    b = np.sum(out_layer)\n",
    "                    aub = np.sum((label_layer + out_layer) / 2)\n",
    "                    anb = np.sum(label_layer * out_layer)\n",
    "\n",
    "                    if a > 0:\n",
    "                        #Volume Overlap Error\n",
    "                        VOE = 1 - (anb / aub)\n",
    "\n",
    "                        #DICE score\n",
    "                        DICE = (2 * anb) / (a + b)\n",
    "\n",
    "                        #Relative Volume Difference\n",
    "                        RVD = (b - a) / a\n",
    "\n",
    "                        meanVOE += VOE\n",
    "                        meanDICE += DICE\n",
    "                        meanRVD += RVD\n",
    "\n",
    "                        num_valid_data += 1\n",
    "\n",
    "                progress.update(1)\n",
    "\n",
    "meanVOE /= num_valid_data\n",
    "print('VOE:  ', meanVOE)\n",
    "meanDICE /= num_valid_data\n",
    "print('DICE: ', meanDICE)\n",
    "meanRVD /= num_valid_data\n",
    "print('RVD:  ', meanRVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    Reader.Liver3Layer(\n",
    "        augment = False\n",
    "    ),\n",
    "    config.batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one part\n",
    "training = False\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "num_valid_data = 0\n",
    "meanVOE = 0\n",
    "meanDICE = 0\n",
    "meanRVD = 0\n",
    "\n",
    "with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "    progress.set_description('Testing')\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        image, label = Reader.Liver3Layer(augment=False).__getitem__(5504)\n",
    "        \n",
    "        image = image.unsqueeze(0)\n",
    "        image = image.float()\n",
    "        image = image.to(device)\n",
    "\n",
    "        label = label.unsqueeze(0)\n",
    "        label = label.float()\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        if training:\n",
    "            raise Exception('There\\'s no Training code available.')\n",
    "        else:\n",
    "            input_image = image.cpu().data\n",
    "            input_image = input_image.view(-1, 256, 256)\n",
    "            input_image = input_image.numpy()\n",
    "            input_image = input_image.squeeze()\n",
    "            input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "            input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "            input_image = [np.array(layer) for layer in input_image]\n",
    "            input_image = np.asarray(input_image)\n",
    "            input_image[input_image < 0] = 0\n",
    "            input_image *= 255\n",
    "            input_depth = len(input_image)\n",
    "            input_image = input_image.repeat(3, axis=0)\n",
    "            input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "\n",
    "            out_image = output.cpu().data\n",
    "            out_image = out_image.view(-1, 64, 64)\n",
    "            out_image = out_image.numpy()\n",
    "            out_image = out_image.squeeze()\n",
    "            out_depth = len(out_image)\n",
    "            out_image = out_image.repeat(3, axis=0)\n",
    "            out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "\n",
    "            label_image = label.cpu().data\n",
    "            label_image = label_image.view(-1, 64, 64)\n",
    "            label_image = label_image.numpy()\n",
    "            label_image = label_image.squeeze()\n",
    "            label_depth = len(label_image)\n",
    "            label_image = label_image.repeat(3, axis=0)\n",
    "            label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "\n",
    "#                 for out_layer, label_layer in zip(out_image, label_image):\n",
    "#                     out_layer[0][:] = 0 #R\n",
    "#                     out_layer[1] = label_layer[1] #G\n",
    "#                     out_layer[2][:] = 0 #B\n",
    "\n",
    "            visual.images(\n",
    "                tensor=input_image, nrow=12,\n",
    "                win='input',\n",
    "                opts=dict(title='input')\n",
    "            )\n",
    "            visual.images(\n",
    "                tensor=out_image, nrow=12,\n",
    "                win='output',\n",
    "                opts=dict(title='output')\n",
    "            )\n",
    "            visual.images(\n",
    "                tensor=label_image, nrow=12,\n",
    "                win='label',\n",
    "                opts=dict(title='label')\n",
    "            )\n",
    "\n",
    "            #threshold\n",
    "            out_image = np.ceil(out_image - 0.5)\n",
    "\n",
    "            for label_layer, out_layer in zip(label_image, out_image):\n",
    "                    #BASIC values\n",
    "                    a = np.sum(label_layer)\n",
    "                    b = np.sum(out_layer)\n",
    "                    aub = np.sum((label_layer + out_layer) / 2)\n",
    "                    anb = np.sum(label_layer * out_layer)\n",
    "\n",
    "                    if a > 0:\n",
    "                        #Volume Overlap Error\n",
    "                        VOE = 1 - (anb / aub)\n",
    "\n",
    "                        #DICE score\n",
    "                        DICE = (2 * anb) / (a + b)\n",
    "\n",
    "                        #Relative Volume Difference\n",
    "                        RVD = (b - a) / a\n",
    "\n",
    "                        meanVOE += VOE\n",
    "                        meanDICE += DICE\n",
    "                        meanRVD += RVD\n",
    "\n",
    "                        num_valid_data += 1\n",
    "\n",
    "            progress.update(1)\n",
    "\n",
    "meanVOE /= num_valid_data\n",
    "print('VOE:  ', meanVOE)\n",
    "meanDICE /= num_valid_data\n",
    "print('DICE: ', meanDICE)\n",
    "meanRVD /= num_valid_data\n",
    "print('RVD:  ', meanRVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in loader:\n",
    "    input_image = images.cpu().data\n",
    "    input_image = input_image.view(-1, config.scale, config.scale)\n",
    "    input_image = input_image.numpy()\n",
    "    input_image = input_image.squeeze()\n",
    "    input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "    input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "    input_image = [np.array(layer) for layer in input_image]\n",
    "    input_image = np.asarray(input_image)\n",
    "    input_image *= 255\n",
    "    input_image = np.clip(input_image, 0, 255)\n",
    "    input_depth = len(input_image)\n",
    "    input_image = input_image.repeat(3, axis=0)\n",
    "    input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "\n",
    "    label_image = labels.cpu().data\n",
    "    label_image = label_image.view(-1, config.scale, config.scale)\n",
    "    label_image = label_image.numpy()\n",
    "    label_image = label_image.squeeze()\n",
    "    label_image = [Image.fromarray(layer, 'F') for layer in label_image]\n",
    "    label_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in label_image]\n",
    "    label_image = [np.array(layer) for layer in label_image]\n",
    "    label_image = np.asarray(label_image)\n",
    "    label_image *= 255\n",
    "    label_image = np.clip(label_image, 0, 255)\n",
    "    label_depth = len(label_image)\n",
    "    label_image = label_image.repeat(3, axis=0)\n",
    "    label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "\n",
    "    visual.images(\n",
    "        tensor=input_image, nrow=6,\n",
    "        win='input',\n",
    "        opts=dict(title='input')\n",
    "    )\n",
    "\n",
    "    visual.images(\n",
    "        tensor=label_image, nrow=6,\n",
    "        win='label',\n",
    "        opts=dict(title='label')\n",
    "    )\n",
    "    \n",
    "    print('asdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
