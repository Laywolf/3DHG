{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import os\n",
    "import imageio\n",
    "from PIL import Image\n",
    "\n",
    "from tqdm import tqdm\n",
    "from visdom import Visdom\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import Reader\n",
    "\n",
    "from dotmap import DotMap\n",
    "\n",
    "config = DotMap({\n",
    "    \"training\": True,\n",
    "    \"batch\": 32,\n",
    "    \"workers\": 0,\n",
    "    \"epoch\": 400\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1x1 convolution\n",
    "def conv_one(in_channel, out_channel):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm3d(in_channel),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv3d(in_channel, out_channel, 1, bias=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# residual block\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel=None):\n",
    "        super(Residual, self).__init__()\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        \n",
    "        if out_channel is None:\n",
    "            out_channel = in_channel\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            conv_one(in_channel, out_channel // 2),\n",
    "            nn.BatchNorm3d(out_channel // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv3d(out_channel // 2, out_channel // 2, 3, padding=1, bias=False),\n",
    "            conv_one(out_channel // 2, out_channel)\n",
    "        )\n",
    "        \n",
    "        self.skip_layer = None\n",
    "        if in_channel != out_channel:\n",
    "            self.skip_layer = nn.Conv3d(in_channel, out_channel, 1)\n",
    "        \n",
    "        self.out_relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        skip = x\n",
    "        \n",
    "        out = self.conv_block(x)\n",
    "        \n",
    "        if self.skip_layer is not None:\n",
    "            skip = self.skip_layer(x)\n",
    "        \n",
    "        out += skip\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourglass\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, size, channels):\n",
    "        super(Hourglass, self).__init__()\n",
    "        self.size = size\n",
    "        self.channels = channels\n",
    "        \n",
    "        self.skip_layers = nn.ModuleList([Residual(self.channels) for _ in range(self.size)])\n",
    "        self.low_layers = nn.ModuleList([Residual(self.channels) for _ in range(self.size)])\n",
    "        self.mid = Residual(self.channels)\n",
    "        self.up_layers = nn.ModuleList([Residual(self.channels) for _ in range(self.size)])\n",
    "        self.max_pool = nn.MaxPool3d((1, 2, 2), stride=(1, 2, 2))\n",
    "        self.upsample = nn.Upsample(scale_factor=(1, 2, 2), mode='trilinear', align_corners=False)\n",
    "        # nearest not working with tuple(1, 2, 2). so bilinear\n",
    "\n",
    "    def forward(self, x):\n",
    "        inner = x\n",
    "\n",
    "        skip_outputs = list()\n",
    "        for skip, low in zip(self.skip_layers, self.low_layers):\n",
    "            s = skip(inner)\n",
    "            skip_outputs.append(s)\n",
    "            inner = self.max_pool(inner)\n",
    "            inner = low(inner)\n",
    "        \n",
    "        out = self.mid(inner)\n",
    "\n",
    "        for skip, up in zip(reversed(skip_outputs), reversed(self.up_layers)):\n",
    "            out = skip + self.upsample(up(out))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, features, internal_size=4):\n",
    "        super(Model, self).__init__()\n",
    "        self.features = features\n",
    "        self.internal_size = internal_size\n",
    "        \n",
    "        self.init_conv = nn.Sequential(\n",
    "            nn.Conv3d(1, 8, 7, stride=(1, 2, 2), padding=3, bias=False),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU(),\n",
    "            Residual(8, 16),\n",
    "            nn.MaxPool3d((1, 2, 2), stride=(1, 2, 2)),\n",
    "            Residual(16, 32),\n",
    "            Residual(32, self.features)\n",
    "        )\n",
    "        \n",
    "        self.hourglass = Hourglass(self.internal_size, self.features)\n",
    "        \n",
    "        self.out_conv = nn.Sequential(\n",
    "            Residual(self.features, self.features),\n",
    "            conv_one(self.features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        init = self.init_conv(x)\n",
    "           \n",
    "        hg = self.hourglass(init)\n",
    "        \n",
    "        out = self.out_conv(hg)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    Reader.Liver3LayerSH(\n",
    "        augment = True\n",
    "    ),\n",
    "    config.batch,\n",
    "    shuffle=(config.training),\n",
    "    pin_memory=True,\n",
    "    num_workers=config.workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjdtn5683/.conda/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py:365: UserWarning: ONNX export failed on ATen operator max_pool3d because torch.onnx.symbolic.max_pool3d does not exist\n",
      "  .format(op_name, op_name))\n",
      "/home/tjdtn5683/.conda/envs/pytorch/lib/python3.6/site-packages/torch/onnx/utils.py:365: UserWarning: ONNX export failed on ATen operator upsample_trilinear3d because torch.onnx.symbolic.upsample_trilinear3d does not exist\n",
      "  .format(op_name, op_name))\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model = Model(64)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.0001)#lr=0.00025)\n",
    "criterion = nn.BCELoss(torch.ones(config.batch, dtype=torch.float64))\n",
    "# cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "training = True\n",
    "\n",
    "visual = Visdom()\n",
    "writer = SummaryWriter()\n",
    "\n",
    "#Batch, Channel, Depth, Height, Width\n",
    "dummy_input = torch.autograd.Variable(\n",
    "    torch.rand(config.batch, 1, 3, 256, 256)\n",
    ")\n",
    "dummy_input = dummy_input.to(device)\n",
    "writer.add_graph(model, (dummy_input, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 613/613 [10:10<00:00,  1.32 iter/s, loss=0.475]\n",
      "Epoch 2: 100%|██████████| 613/613 [10:01<00:00,  1.35 iter/s, loss=0.383]\n",
      "Epoch 3: 100%|██████████| 613/613 [09:58<00:00,  1.34 iter/s, loss=0.019]\n",
      "Epoch 4: 100%|██████████| 613/613 [09:52<00:00,  1.37 iter/s, loss=0.619]\n",
      "Epoch 5: 100%|██████████| 613/613 [09:49<00:00,  1.37 iter/s, loss=0.0118]\n",
      "Epoch 6: 100%|██████████| 613/613 [09:49<00:00,  1.36 iter/s, loss=0.463]\n",
      "Epoch 7: 100%|██████████| 613/613 [09:50<00:00,  1.37 iter/s, loss=0.88]\n",
      "Epoch 8: 100%|██████████| 613/613 [09:45<00:00,  1.38 iter/s, loss=0.00806]\n",
      "Epoch 9: 100%|██████████| 613/613 [09:42<00:00,  1.39 iter/s, loss=0.0118]\n",
      "Epoch 10: 100%|██████████| 613/613 [09:42<00:00,  1.37 iter/s, loss=0.57]\n",
      "Epoch 11: 100%|██████████| 613/613 [09:39<00:00,  1.37 iter/s, loss=0.0179]\n",
      "Epoch 12: 100%|██████████| 613/613 [09:38<00:00,  1.39 iter/s, loss=0.00937]\n",
      "Epoch 13: 100%|██████████| 613/613 [09:38<00:00,  1.39 iter/s, loss=0.00568]\n",
      "Epoch 14: 100%|██████████| 613/613 [09:38<00:00,  1.40 iter/s, loss=0.271]\n",
      "Epoch 15: 100%|██████████| 613/613 [09:38<00:00,  1.39 iter/s, loss=0.00866]\n",
      "Epoch 16: 100%|██████████| 613/613 [09:39<00:00,  1.39 iter/s, loss=0.0101]\n",
      "Epoch 17: 100%|██████████| 613/613 [09:36<00:00,  1.40 iter/s, loss=0.00469]\n",
      "Epoch 18: 100%|██████████| 613/613 [09:38<00:00,  1.39 iter/s, loss=0.319]\n",
      "Epoch 19: 100%|██████████| 613/613 [09:37<00:00,  1.39 iter/s, loss=0.00437]\n",
      "Epoch 20: 100%|██████████| 613/613 [09:35<00:00,  1.41 iter/s, loss=0.17]\n",
      "Epoch 21: 100%|██████████| 613/613 [09:36<00:00,  1.39 iter/s, loss=0.441]\n",
      "Epoch 22: 100%|██████████| 613/613 [09:35<00:00,  1.40 iter/s, loss=0.00291]\n",
      "Epoch 23: 100%|██████████| 613/613 [09:33<00:00,  1.39 iter/s, loss=0.462]\n",
      "Epoch 24: 100%|██████████| 613/613 [09:35<00:00,  1.39 iter/s, loss=0.512]\n",
      "Epoch 25: 100%|██████████| 613/613 [09:35<00:00,  1.40 iter/s, loss=0.213]\n",
      "Epoch 26: 100%|██████████| 613/613 [09:32<00:00,  1.42 iter/s, loss=0.00311]\n",
      "Epoch 27: 100%|██████████| 613/613 [09:31<00:00,  1.41 iter/s, loss=0.00264]\n",
      "Epoch 28: 100%|██████████| 613/613 [09:35<00:00,  1.41 iter/s, loss=0.00362]\n",
      "Epoch 29: 100%|██████████| 613/613 [09:36<00:00,  1.39 iter/s, loss=0.00888]\n",
      "Epoch 30: 100%|██████████| 613/613 [09:33<00:00,  1.40 iter/s, loss=0.00396]\n",
      "Epoch 31: 100%|██████████| 613/613 [09:33<00:00,  1.39 iter/s, loss=0.00202]\n",
      "Epoch 32: 100%|██████████| 613/613 [09:34<00:00,  1.42 iter/s, loss=0.00443]\n",
      "Epoch 33: 100%|██████████| 613/613 [09:29<00:00,  1.40 iter/s, loss=0.176]\n",
      "Epoch 34: 100%|██████████| 613/613 [09:31<00:00,  1.40 iter/s, loss=0.276]\n",
      "Epoch 35: 100%|██████████| 613/613 [09:33<00:00,  1.38 iter/s, loss=0.00259]\n",
      "Epoch 36: 100%|██████████| 613/613 [09:34<00:00,  1.41 iter/s, loss=0.665]\n",
      "Epoch 37: 100%|██████████| 613/613 [09:33<00:00,  1.40 iter/s, loss=0.00243]\n",
      "Epoch 38: 100%|██████████| 613/613 [09:33<00:00,  1.41 iter/s, loss=0.196]\n",
      "Epoch 39: 100%|██████████| 613/613 [09:30<00:00,  1.42 iter/s, loss=0.924]\n",
      "Epoch 40: 100%|██████████| 613/613 [09:31<00:00,  1.40 iter/s, loss=0.229]\n",
      "Epoch 41: 100%|██████████| 613/613 [09:33<00:00,  1.40 iter/s, loss=0.3]\n",
      "Epoch 42: 100%|██████████| 613/613 [09:31<00:00,  1.40 iter/s, loss=0.364]\n",
      "Epoch 43: 100%|██████████| 613/613 [09:33<00:00,  1.41 iter/s, loss=0.748]\n",
      "Epoch 44: 100%|██████████| 613/613 [09:32<00:00,  1.41 iter/s, loss=1.12]\n",
      "Epoch 45: 100%|██████████| 613/613 [09:33<00:00,  1.41 iter/s, loss=0.269]\n",
      "Epoch 46: 100%|██████████| 613/613 [09:30<00:00,  1.41 iter/s, loss=0.329]\n",
      "Epoch 47: 100%|██████████| 613/613 [09:30<00:00,  1.43 iter/s, loss=0.00309]\n",
      "Epoch 48: 100%|██████████| 613/613 [09:30<00:00,  1.41 iter/s, loss=0.904]\n",
      "Epoch 49: 100%|██████████| 613/613 [09:30<00:00,  1.40 iter/s, loss=0.00151]\n",
      "Epoch 50: 100%|██████████| 613/613 [09:32<00:00,  1.41 iter/s, loss=0.69]\n",
      "Epoch 51:  49%|████▉     | 302/613 [04:40<04:53,  1.06 iter/s, loss=0.373]"
     ]
    }
   ],
   "source": [
    "training = True\n",
    "\n",
    "counter = 0\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "for epoch in range(1, config.epoch):\n",
    "    with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "        progress.set_description('Epoch %d' % epoch)\n",
    "        \n",
    "        with torch.set_grad_enabled(training):\n",
    "            for images, labels in loader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                images = images.float()\n",
    "                input_image = images\n",
    "                images = images.to(device)\n",
    "\n",
    "                labels = labels.float()\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                output = model(images)\n",
    "                \n",
    "                if training:\n",
    "                    out_image = output.cpu().data\n",
    "                    label_image = labels.cpu().data\n",
    "                    \n",
    "                    weight = []\n",
    "                    for images in label_image.numpy().squeeze():\n",
    "                        weight_batch = []\n",
    "                        for image in images:\n",
    "                            value = np.ceil(image)\n",
    "                            if np.sum(image) > 0:\n",
    "                                value *= (np.sum(1-image) / np.sum(image))-1\n",
    "                            value += 1\n",
    "                            weight_batch.append(value)\n",
    "                        weight.append(weight_batch)\n",
    "                    \n",
    "                    weight = np.array(weight)\n",
    "                    \n",
    "                    criterion.weight = torch.tensor(weight).to(device)\n",
    "                    \n",
    "                    loss = criterion(output.squeeze(), labels.squeeze())\n",
    "                    loss = torch.mean(loss)\n",
    "                    loss.backward()\n",
    "                    \n",
    "                    optimizer.step()\n",
    "                    progress.set_postfix(loss=float(loss.item()))\n",
    "                    \n",
    "                    input_image = input_image.cpu().data\n",
    "                    input_image = input_image.view(-1, 256, 256)\n",
    "                    input_image = input_image.numpy()\n",
    "                    input_image = input_image.squeeze()\n",
    "                    input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "                    input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "                    input_image = [np.array(layer) for layer in input_image]\n",
    "                    input_image = np.asarray(input_image)\n",
    "                    input_image[input_image < 0] = 0\n",
    "                    input_image *= 255\n",
    "                    input_depth = len(input_image)\n",
    "                    input_image = input_image.repeat(3, axis=0)\n",
    "                    input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "                    \n",
    "                    out_image = out_image.view(-1, 64, 64)\n",
    "                    out_image = out_image.numpy()\n",
    "                    out_image = out_image.squeeze()\n",
    "                    out_depth = len(out_image)\n",
    "                    out_image = out_image.repeat(3, axis=0)\n",
    "                    out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "                    \n",
    "                    label_image = label_image.view(-1, 64, 64)\n",
    "                    label_image = label_image.numpy()\n",
    "                    label_image = label_image.squeeze()\n",
    "                    label_depth = len(label_image)\n",
    "                    label_image = label_image.repeat(3, axis=0)\n",
    "                    label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "                    \n",
    "                    visual.images(\n",
    "                        tensor=input_image, nrow=9,\n",
    "                        win='input',\n",
    "                        opts=dict(title='input')\n",
    "                    )\n",
    "                    \n",
    "                    visual.images(\n",
    "                        tensor=out_image, nrow=9,\n",
    "                        win='output',\n",
    "                        opts=dict(title='output')\n",
    "                    )\n",
    "                    visual.images(\n",
    "                        tensor=label_image, nrow=9,\n",
    "                        win='label',\n",
    "                        opts=dict(title='label')\n",
    "                    )\n",
    "                    \n",
    "                    writer.add_scalar('data/loss', float(loss.item()), counter)\n",
    "\n",
    "                    progress.update(1)\n",
    "                    \n",
    "                    counter += 1\n",
    "                    \n",
    "                else:\n",
    "                    raise Exception('There\\'s no Validation code available.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "save_epoch = config.epoch\n",
    "save_epoch = 0\n",
    "torch.save({\n",
    "    'epoch': save_epoch,\n",
    "    'state': model.state_dict(),\n",
    "    'optimizer': optimizer.state_dict()\n",
    "}, 'save/3_'+str(save_epoch)+'.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = Model(64)\n",
    "pretrained_model = torch.load('save/3_100_cb.save')\n",
    "model.load_state_dict(pretrained_model['state'])\n",
    "\n",
    "model = model.eval()\n",
    "# cuda\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "training = False\n",
    "\n",
    "visual = Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    Reader.LiverData(\n",
    "        augment = False,\n",
    "        paths = ['Data/3Dircadb/']\n",
    "    ),\n",
    "    1,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a CT\n",
    "training = False\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "num_valid_data = 0\n",
    "meanVOE = 0\n",
    "meanDICE = 0\n",
    "meanRVD = 0\n",
    "DICE_list = []\n",
    "\n",
    "with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "    progress.set_description('Testing')\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for image, label in loader:\n",
    "            \n",
    "            image = image.float()\n",
    "            image = image.squeeze()\n",
    "            \n",
    "            output = []\n",
    "            \n",
    "            for index in range(0, len(image), 3):\n",
    "                final = 0\n",
    "                if index+3 > len(image):\n",
    "                    final = index+3 - len(image)\n",
    "                    index = len(image) - 3\n",
    "                    \n",
    "                input_cell = image[index:index+3]\n",
    "                input_cell = input_cell.unsqueeze(0).unsqueeze(0)\n",
    "                input_cell = input_cell.to(device)\n",
    "                out_cell = model(input_cell)\n",
    "                out_cell = out_cell.squeeze()\n",
    "                if final is 0:\n",
    "                    feed = out_cell.cpu().data.numpy()\n",
    "                    for layer in feed:\n",
    "                        output.append(layer)\n",
    "                else:\n",
    "                    feed = out_cell.narrow(0, final, 3-final)\n",
    "                    feed = feed.cpu().data.numpy()\n",
    "                    for layer in feed:\n",
    "                        output.append(layer)\n",
    "            \n",
    "            label = label.float()\n",
    "            label = label.to(device)\n",
    "\n",
    "            if training:\n",
    "                raise Exception('There\\'s no Training code available.')\n",
    "            else:\n",
    "                input_image = image.cpu().data\n",
    "                input_image = input_image.view(-1, 256, 256)\n",
    "                input_image = input_image.numpy()\n",
    "                input_image = input_image.squeeze()\n",
    "                input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "                input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "                input_image = [np.array(layer) for layer in input_image]\n",
    "                input_image = np.asarray(input_image)\n",
    "                input_image[input_image < 0] = 0\n",
    "                input_image *= 255\n",
    "                input_depth = len(input_image)\n",
    "                input_image = input_image.repeat(3, axis=0)\n",
    "                input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "                \n",
    "                out_image = np.asarray(output)\n",
    "                out_image = out_image.reshape(-1, 64, 64)\n",
    "                out_image = out_image.squeeze()\n",
    "                out_depth = len(out_image)\n",
    "                out_image = out_image.repeat(3, axis=0)\n",
    "                out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "                \n",
    "                label_image = label.cpu().data\n",
    "                label_image = label_image.view(-1, 64, 64)\n",
    "                label_image = label_image.numpy()\n",
    "                label_image = label_image.squeeze()\n",
    "                label_depth = len(label_image)\n",
    "                label_image = label_image.repeat(3, axis=0)\n",
    "                label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "                \n",
    "#                 for out_layer, label_layer in zip(out_image, label_image):\n",
    "#                     out_layer[0][:] = 0 #R\n",
    "#                     out_layer[1] = label_layer[1] #G\n",
    "#                     out_layer[2][:] = 0 #B\n",
    "\n",
    "                visual.images(\n",
    "                    tensor=input_image, nrow=9,\n",
    "                    win='input',\n",
    "                    opts=dict(title='input')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=out_image, nrow=9,\n",
    "                    win='output',\n",
    "                    opts=dict(title='output')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=label_image, nrow=9,\n",
    "                    win='label',\n",
    "                    opts=dict(title='label')\n",
    "                )\n",
    "\n",
    "                #threshold\n",
    "                out_image = np.ceil(out_image - 0.6)\n",
    "\n",
    "                a = np.sum(label_image)\n",
    "                b = np.sum(out_image)\n",
    "                aub = np.sum((label_image + out_image) / 2)\n",
    "                anb = np.sum(label_image * out_image)\n",
    "\n",
    "                if a > 1:\n",
    "                    #Volume Overlap Error\n",
    "                    VOE = 1 - (anb / aub)\n",
    "\n",
    "                    #DICE score\n",
    "                    DICE = (2 * anb) / (a + b)\n",
    "\n",
    "                    #Relative Volume Difference\n",
    "                    RVD = (b - a) / a\n",
    "\n",
    "                    meanVOE += VOE\n",
    "                    meanDICE += DICE\n",
    "                    meanRVD += RVD\n",
    "\n",
    "                    num_valid_data += 1\n",
    "                    \n",
    "                    DICE_list.append(DICE)\n",
    "                \n",
    "                progress.set_postfix(loss=float(DICE))\n",
    "\n",
    "                progress.update(1)\n",
    "\n",
    "meanVOE /= num_valid_data\n",
    "print('VOE:  ', meanVOE)\n",
    "meanDICE /= num_valid_data\n",
    "print('DICE: ', meanDICE)\n",
    "meanRVD /= num_valid_data\n",
    "print('RVD:  ', meanRVD)\n",
    "print(DICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "for value in DICE_list:\n",
    "    print(value)\n",
    "    if value > 0.1:\n",
    "        num += 1\n",
    "print(sum(DICE_list)/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "training = False\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "num_valid_data = 0\n",
    "meanVOE = 0\n",
    "meanDICE = 0\n",
    "meanRVD = 0\n",
    "\n",
    "with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "    progress.set_description('Testing')\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        for image, label in loader:\n",
    "            \n",
    "            image = image.float()\n",
    "            image = image.to(device)\n",
    "            \n",
    "            label = label.float()\n",
    "            label = label.to(device)\n",
    "            \n",
    "            output = model(image)\n",
    "            \n",
    "            if training:\n",
    "                raise Exception('There\\'s no Training code available.')\n",
    "            else:\n",
    "                input_image = image.cpu().data\n",
    "                input_image = input_image.view(-1, 256, 256)\n",
    "                input_image = input_image.numpy()\n",
    "                input_image = input_image.squeeze()\n",
    "                input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "                input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "                input_image = [np.array(layer) for layer in input_image]\n",
    "                input_image = np.asarray(input_image)\n",
    "                input_image[input_image < 0] = 0\n",
    "                input_image *= 255\n",
    "                input_depth = len(input_image)\n",
    "                input_image = input_image.repeat(3, axis=0)\n",
    "                input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "                \n",
    "                out_image = output.cpu().data\n",
    "                out_image = out_image.view(-1, 64, 64)\n",
    "                out_image = out_image.numpy()\n",
    "                out_image = out_image.squeeze()\n",
    "                out_depth = len(out_image)\n",
    "                out_image = out_image.repeat(3, axis=0)\n",
    "                out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "                \n",
    "                label_image = label.cpu().data\n",
    "                label_image = label_image.view(-1, 64, 64)\n",
    "                label_image = label_image.numpy()\n",
    "                label_image = label_image.squeeze()\n",
    "                label_depth = len(label_image)\n",
    "                label_image = label_image.repeat(3, axis=0)\n",
    "                label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "                \n",
    "#                 for out_layer, label_layer in zip(out_image, label_image):\n",
    "#                     out_layer[0][:] = 0 #R\n",
    "#                     out_layer[1] = label_layer[1] #G\n",
    "#                     out_layer[2][:] = 0 #B\n",
    "\n",
    "                visual.images(\n",
    "                    tensor=input_image, nrow=12,\n",
    "                    win='input',\n",
    "                    opts=dict(title='input')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=out_image, nrow=12,\n",
    "                    win='output',\n",
    "                    opts=dict(title='output')\n",
    "                )\n",
    "                visual.images(\n",
    "                    tensor=label_image, nrow=12,\n",
    "                    win='label',\n",
    "                    opts=dict(title='label')\n",
    "                )\n",
    "\n",
    "                #threshold\n",
    "                out_image = np.ceil(out_image - 0.5)\n",
    "\n",
    "                for label_layer, out_layer in zip(label_image, out_image):\n",
    "                    #BASIC values\n",
    "                    a = np.sum(label_layer)\n",
    "                    b = np.sum(out_layer)\n",
    "                    aub = np.sum((label_layer + out_layer) / 2)\n",
    "                    anb = np.sum(label_layer * out_layer)\n",
    "\n",
    "                    if a > 0:\n",
    "                        #Volume Overlap Error\n",
    "                        VOE = 1 - (anb / aub)\n",
    "\n",
    "                        #DICE score\n",
    "                        DICE = (2 * anb) / (a + b)\n",
    "\n",
    "                        #Relative Volume Difference\n",
    "                        RVD = (b - a) / a\n",
    "\n",
    "                        meanVOE += VOE\n",
    "                        meanDICE += DICE\n",
    "                        meanRVD += RVD\n",
    "\n",
    "                        num_valid_data += 1\n",
    "\n",
    "                progress.update(1)\n",
    "\n",
    "meanVOE /= num_valid_data\n",
    "print('VOE:  ', meanVOE)\n",
    "meanDICE /= num_valid_data\n",
    "print('DICE: ', meanDICE)\n",
    "meanRVD /= num_valid_data\n",
    "print('RVD:  ', meanRVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(\n",
    "    Reader.Liver3Layer(\n",
    "        augment = False\n",
    "    ),\n",
    "    config.batch,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=config.workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test one part\n",
    "training = False\n",
    "\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "num_valid_data = 0\n",
    "meanVOE = 0\n",
    "meanDICE = 0\n",
    "meanRVD = 0\n",
    "\n",
    "with tqdm(total=len(loader), unit=' iter', unit_scale=False) as progress:\n",
    "    progress.set_description('Testing')\n",
    "\n",
    "    with torch.set_grad_enabled(training):\n",
    "        image, label = Reader.Liver3Layer(augment=False).__getitem__(5504)\n",
    "        \n",
    "        image = image.unsqueeze(0)\n",
    "        image = image.float()\n",
    "        image = image.to(device)\n",
    "\n",
    "        label = label.unsqueeze(0)\n",
    "        label = label.float()\n",
    "        label = label.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "\n",
    "        if training:\n",
    "            raise Exception('There\\'s no Training code available.')\n",
    "        else:\n",
    "            input_image = image.cpu().data\n",
    "            input_image = input_image.view(-1, 256, 256)\n",
    "            input_image = input_image.numpy()\n",
    "            input_image = input_image.squeeze()\n",
    "            input_image = [Image.fromarray(layer, 'F') for layer in input_image]\n",
    "            input_image = [layer.resize((64, 64), Image.ANTIALIAS) for layer in input_image]\n",
    "            input_image = [np.array(layer) for layer in input_image]\n",
    "            input_image = np.asarray(input_image)\n",
    "            input_image[input_image < 0] = 0\n",
    "            input_image *= 255\n",
    "            input_depth = len(input_image)\n",
    "            input_image = input_image.repeat(3, axis=0)\n",
    "            input_image = np.reshape(input_image, (input_depth, 3, 64, 64))\n",
    "\n",
    "            out_image = output.cpu().data\n",
    "            out_image = out_image.view(-1, 64, 64)\n",
    "            out_image = out_image.numpy()\n",
    "            out_image = out_image.squeeze()\n",
    "            out_depth = len(out_image)\n",
    "            out_image = out_image.repeat(3, axis=0)\n",
    "            out_image = np.reshape(out_image, (out_depth, 3, 64, 64))\n",
    "\n",
    "            label_image = label.cpu().data\n",
    "            label_image = label_image.view(-1, 64, 64)\n",
    "            label_image = label_image.numpy()\n",
    "            label_image = label_image.squeeze()\n",
    "            label_depth = len(label_image)\n",
    "            label_image = label_image.repeat(3, axis=0)\n",
    "            label_image = np.reshape(label_image, (label_depth, 3, 64,64))\n",
    "\n",
    "#                 for out_layer, label_layer in zip(out_image, label_image):\n",
    "#                     out_layer[0][:] = 0 #R\n",
    "#                     out_layer[1] = label_layer[1] #G\n",
    "#                     out_layer[2][:] = 0 #B\n",
    "\n",
    "            visual.images(\n",
    "                tensor=input_image, nrow=12,\n",
    "                win='input',\n",
    "                opts=dict(title='input')\n",
    "            )\n",
    "            visual.images(\n",
    "                tensor=out_image, nrow=12,\n",
    "                win='output',\n",
    "                opts=dict(title='output')\n",
    "            )\n",
    "            visual.images(\n",
    "                tensor=label_image, nrow=12,\n",
    "                win='label',\n",
    "                opts=dict(title='label')\n",
    "            )\n",
    "\n",
    "            #threshold\n",
    "            out_image = np.ceil(out_image - 0.5)\n",
    "\n",
    "            for label_layer, out_layer in zip(label_image, out_image):\n",
    "                    #BASIC values\n",
    "                    a = np.sum(label_layer)\n",
    "                    b = np.sum(out_layer)\n",
    "                    aub = np.sum((label_layer + out_layer) / 2)\n",
    "                    anb = np.sum(label_layer * out_layer)\n",
    "\n",
    "                    if a > 0:\n",
    "                        #Volume Overlap Error\n",
    "                        VOE = 1 - (anb / aub)\n",
    "\n",
    "                        #DICE score\n",
    "                        DICE = (2 * anb) / (a + b)\n",
    "\n",
    "                        #Relative Volume Difference\n",
    "                        RVD = (b - a) / a\n",
    "\n",
    "                        meanVOE += VOE\n",
    "                        meanDICE += DICE\n",
    "                        meanRVD += RVD\n",
    "\n",
    "                        num_valid_data += 1\n",
    "\n",
    "            progress.update(1)\n",
    "\n",
    "meanVOE /= num_valid_data\n",
    "print('VOE:  ', meanVOE)\n",
    "meanDICE /= num_valid_data\n",
    "print('DICE: ', meanDICE)\n",
    "meanRVD /= num_valid_data\n",
    "print('RVD:  ', meanRVD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
